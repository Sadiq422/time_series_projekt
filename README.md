README
---

# ğŸš€ **Time Series Analysis & Forecasting Dashboard**

---


Eine End-to-End Machine Learning Pipeline zur Analyse und Vorhersage komplexer Zeitreihen fÃ¼r den Einzelhandel. Dieses Projekt kombiniert modernste Deep-Learning-Verfahren (LSTM) mit klassischen statistischen Modellen und Gradient Boosting in einem professionellen, interaktiven Dashboard.

---

# ğŸ“Œ **Highlights**
Enterprise-Ready Dashboard: Professionelle Dark Mode BenutzeroberflÃ¤che mit Echtzeit-Visualisierungen

---

# ğŸ“ Projektstruktur & Navigation

Das Projekt folgt einer modularen Architektur, die Datenverarbeitung, Modellierung und UI-Layer klar trennt. Die Struktur sieht genau wie folgt aus:

```text
time_series_projekt/<br/>
â”œâ”€â”€ app/                          # Streamlit Dashboard & UI Logik<br/>
â”‚   â”œâ”€â”€ app.py                      # Hauptanwendung (Dark Mode)<br/>
â”‚   â”œâ”€â”€ app_backup.py               # Backup der ursprÃ¼nglichen App<br/>
â”‚   â””â”€â”€ bootstrap.py                # UI-Komponenten & Styling<br/>
â”‚<br/>
â”œâ”€â”€ notebooks/                    # Forschungs- & Entwicklungs-Pipeline<br/>
â”‚   â”œâ”€â”€ 01_preprocessing.ipynb      # Datenreinigung & Transformation<br/>
â”‚   â”œâ”€â”€ 02_feature_engineering.ipynb# Feature-Generierung<br/>
â”‚   â”œâ”€â”€ 03_data_management.ipynb    # I/O Prozesse<br/>
â”‚   â”œâ”€â”€ 04_lstm_modeling.ipynb      # Deep Learning Modelle<br/>
â”‚   â”œâ”€â”€ 05_xgboost_modeling.ipynb   # Gradient Boosting<br/>
â”‚   â””â”€â”€ 06_arima_analysis.ipynb     # Statistische Baseline<br/>
â”‚<br/>
â”œâ”€â”€ data/                         # Roh- und vorverarbeitete DatensÃ¤tze<br/>
â”‚   â””â”€â”€ filtered/                   # Vorverarbeitete Daten<br/>
â”‚<br/>
â”œâ”€â”€ outputs/                      # Ergebnisse & Exporte<br/>
â”‚   â”œâ”€â”€ forecasts/                  # Vorhersage-Ergebnisse<br/>
â”‚   â”œâ”€â”€ visualizations/             # Automatisch generierte Plots<br/>
â”‚   â””â”€â”€ reports/                    # Analysen & Dokumentation<br/>
â”‚<br/>
â”œâ”€â”€ paths.py                     # Zentrale Pfadverwaltung<br/>
â”œâ”€â”€ utils.py                     # Core Helper Functions<br/>
â”œâ”€â”€ visualizer.py                # Plotting Engine<br/>
â”œâ”€â”€ requirements.txt             # HauptabhÃ¤ngigkeiten<br/>
â”œâ”€â”€ environment.yml              # Conda Environment<br/>
â””â”€â”€ README.md                    # Diese Dokumentation


---

Multi-Modell Ensemble: Kombiniert LSTM, XGBoost und ARIMA fÃ¼r robuste Vorhersagen

Automatisches Feature-Engineering: Lag-Features, Rolling Statistics, Saisonale Dekomposition

Produktionsreife Pipeline: VollstÃ¤ndige ML Pipeline von Datenvorbereitung bis Deployment

Interactive Analytics: Echtzeit-Analyse mit Konfidenzintervallen und Performance-Metriken

---

# ğŸ“Š **Dashboard Features**
ğŸ”— Kernfunktionen
Echtzeit Forecasting: Historische und zukÃ¼nftige Verkaufsprognosen

Performance Monitoring: MAE, RMSE, RÂ² Metriken in Echtzeit

Residuen-Analyse: Detaillierte Fehleranalyse und Diagnostik

Konfidenzintervalle: Statistische Unsicherheitsquantifizierung

---

# ğŸ“ˆ **Visualisierungen**
Interactive Plots: Plotly-basierte interaktive Diagramme

Vergleichende Analysen: TatsÃ¤chliche vs. vorhergesagte Werte

Trend-Analyse: Saisonale Dekomposition und Trenderkennung

Fehlerverteilungen: Histogramme und Residuen-Plots

---

# âš™ï¸ **Konfiguration**
Store & Item Selection: Flexible Auswahl von GeschÃ¤ften und Artikeln

Modell-Parameter: Anpassbare Forecast-Horizonte und Konfidenzniveaus

Export-Funktionen: CSV-Export und Report-Generierung

---

# ğŸ› ï¸ **Technologiestack**

## Machine Learning & Data Science:

TensorFlow/Keras: LSTM Neural Networks fÃ¼r Sequenzvorhersagen

XGBoost: Gradient Boosting fÃ¼r tabulare Daten

Statsmodels: ARIMA und statistische Analysen

Scikit-learn: Feature Engineering und Preprocessing

Pandas & NumPy: Datenmanipulation und -analyse

## Dashboard & Visualisierung:

Streamlit: Interactive Web Application Framework

Plotly: Interaktive Visualisierungen

Matplotlib/Seaborn: Statische Plot-Generierung

## Entwicklung & Deployment:


Python 3.9+: Hauptprogrammiersprache

Git: Versionskontrolle

Conda/Pip: Paketverwaltung

---

# ğŸš€ **Installation**

## Voraussetzungen
Python 3.9 oder hÃ¶her

pip oder conda

---

# ğŸ“– **Verwendung**

Daten hochladen: Laden Sie Ihre Zeitreihendaten im CSV-Format

Modell konfigurieren: WÃ¤hlen Sie Vorhersagehorizont und Konfidenzniveau

Training starten: Lassen Sie das Ensemble-Modell automatisch trainieren

Ergebnisse analysieren: Nutzen Sie die interaktiven Visualisierungen

Exportieren: Speichern Sie Vorhersagen und Berichte

---

# ğŸ“Š **Performance Metriken**

Das System berechnet folgende Metriken automatisch:

MAE (Mean Absolute Error)

RMSE (Root Mean Square Error)

RÂ² (Determinationskoeffizient)

MAPE (Mean Absolute Percentage Error)

---

# ğŸ”§ **Konfiguration**

Anpassbare Parameter in config.py:

Forecast Horizon (1-52 Wochen)

Konfidenzintervalle (80%, 90%, 95%)

Modellgewichtungen (LSTM, XGBoost, ARIMA)

Feature Engineering Parameter

# ğŸ“„ **Lizenz**

---

Dieses Projekt ist unter der MIT-Lizenz lizenziert - siehe LICENSE Datei fÃ¼r Details.

---

ğŸ‘¥ Autoren
Dieses Projekt wurde gemeinsam entwickelt von:
Claudia Tagbo
Sadiq

---

# **ğŸ“ Kontakt**

FÃ¼r Fragen oder Support:
Claudia
E-mail: fotsoclaudia88@gmail.com
Sadiq
qais.sadiq422@gmail.com

